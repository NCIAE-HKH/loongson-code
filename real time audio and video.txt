#!/usr/bin/env python3
# sender.py - é¾™èŠ¯æ¿éŸ³è§†é¢‘å‘é€ç«¯ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
import cv2
import socket
import time
import numpy as np
import logging
import subprocess
import sys
import threading
import os

# ============== é…ç½®åŒºåŸŸ ==============
TARGET_IP = "192.168.1.166"  # æ¥æ”¶ç«¯PCçš„å®é™…IPåœ°å€
VIDEO_PORT = 5002
AUDIO_PORT = 5003
VIDEO_FRAME_WIDTH = 640
VIDEO_FRAME_HEIGHT = 480
VIDEO_FPS = 15                 # ç›®æ ‡å¸§ç‡ï¼ˆæ ¹æ®éœ€æ±‚è°ƒæ•´ï¼‰
AUDIO_SAMPLE_RATE = 44100      # éŸ³é¢‘é‡‡æ ·ç‡
AUDIO_CHANNELS = 1            # éŸ³é¢‘é€šé“æ•°
# =====================================

class MediaStreamer:
    def __init__(self):
        # çŠ¶æ€æ§åˆ¶
        self.active = True
        
        # ç½‘ç»œå¥—æ¥å­—
        self.video_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self.audio_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self.video_socket.setsockopt(socket.SOL_SOCKET, socket.SO_SNDBUF, 10 * 1024 * 1024)
        
        # è§†é¢‘æ€§èƒ½è®¡æ•°å™¨
        self.frame_count = 0
        self.start_time = time.time()
        
        # é…ç½®æ—¥å¿—
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s [%(levelname)s] %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S',
            handlers=[logging.StreamHandler(sys.stdout)]
        )
        
        # åˆå§‹åŒ–æ‘„åƒå¤´
        self.cap = self.initialize_camera()
        
        # åˆå§‹åŒ–éŸ³é¢‘
        self.audio_process = None
        
        logging.info("âœ… å‘é€ç«¯åˆå§‹åŒ–å®Œæˆ")

    def initialize_camera(self):
        """åˆå§‹åŒ–æ‘„åƒå¤´å¹¶è®¾ç½®å‚æ•°"""
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            logging.error("âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´ï¼Œåˆ›å»ºè™šæ‹Ÿæº")
            return self.create_virtual_camera()
            
        # å°è¯•è®¾ç½®åˆ†è¾¨ç‡
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, VIDEO_FRAME_WIDTH)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, VIDEO_FRAME_HEIGHT)
        
        # æ‰“å°å®é™…åˆ†è¾¨ç‡
        actual_width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)
        actual_height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)
        logging.info(f"ğŸ“· æ‘„åƒå¤´åˆ†è¾¨ç‡: {int(actual_width)}x{int(actual_height)}")
        
        return cap

    def create_virtual_camera(self):
        """åˆ›å»ºè™šæ‹Ÿæ‘„åƒå¤´"""
        class VirtualCamera:
            def __init__(self):
                self.frame_count = 0
                
            def read(self):
                img = np.zeros((VIDEO_FRAME_HEIGHT, VIDEO_FRAME_WIDTH, 3), dtype=np.uint8)
                cv2.putText(img, "Virtual Camera", 
                           (50, VIDEO_FRAME_HEIGHT//2 - 20), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
                cv2.putText(img, "Press 'q' to quit", 
                           (50, VIDEO_FRAME_HEIGHT//2 + 30), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 1)
                self.frame_count += 1
                return True, img
                
            def isOpened(self):
                return True
                
            def release(self):
                pass
        
        return VirtualCamera()

    def start_audio_capture(self):
        """å¯åŠ¨ALSAéŸ³é¢‘é‡‡é›†"""
        try:
            # æ£€æŸ¥arecordæ˜¯å¦å¯ç”¨
            subprocess.check_call(["arecord", "--version"], 
                                 stdout=subprocess.DEVNULL, 
                                 stderr=subprocess.DEVNULL)
            
            # æ„å»ºarecordå‘½ä»¤
            cmd = [
                "arecord",
                "-f", "S16_LE",      # 16ä½å°ç«¯æ ¼å¼
                "-r", str(AUDIO_SAMPLE_RATE),
                "-c", str(AUDIO_CHANNELS),
                "-t", "raw",         # åŸå§‹æ ¼å¼
                "-"                  # è¾“å‡ºåˆ°stdout
            ]
            
            # å¯åŠ¨éŸ³é¢‘é‡‡é›†è¿›ç¨‹
            self.audio_process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE
            )
            
            logging.info(f"ğŸ™ï¸ éŸ³é¢‘é‡‡é›†å·²å¯åŠ¨ @ {AUDIO_SAMPLE_RATE}Hz")
            
            # å¯åŠ¨éŸ³é¢‘å‘é€çº¿ç¨‹
            audio_thread = threading.Thread(target=self.audio_sending_thread)
            audio_thread.daemon = True
            audio_thread.start()
            
            return True
            
        except (FileNotFoundError, subprocess.CalledProcessError):
            logging.error("âŒ arecordå‘½ä»¤ä¸å¯ç”¨ï¼Œè·³è¿‡éŸ³é¢‘é‡‡é›†")
            logging.info("è¯·å®‰è£…alsa-utils: sudo apt install alsa-utils")
            return False

    def audio_sending_thread(self):
        """éŸ³é¢‘å‘é€çº¿ç¨‹"""
        logging.info("ğŸ”Š éŸ³é¢‘å‘é€çº¿ç¨‹å¯åŠ¨")
        audio_packet_size = 1024 * AUDIO_CHANNELS * 2  # 16ä½ * é€šé“æ•°
        
        while self.active and self.audio_process.poll() is None:
            try:
                # è¯»å–éŸ³é¢‘æ•°æ®
                audio_data = self.audio_process.stdout.read(audio_packet_size)
                if audio_data:
                    self.audio_socket.sendto(audio_data, (TARGET_IP, AUDIO_PORT))
                else:
                    time.sleep(0.01)
            except Exception as e:
                logging.error(f"ğŸ”´ éŸ³é¢‘å‘é€é”™è¯¯: {str(e)}")
                break

    def video_capture_thread(self):
        """è§†é¢‘æ•è·çº¿ç¨‹"""
        logging.info("ğŸ“¹ è§†é¢‘æ•è·çº¿ç¨‹å¯åŠ¨")
        
        # å¸§ç‡æ§åˆ¶å˜é‡
        frame_interval = 1.0 / VIDEO_FPS
        last_frame_time = time.time()
        
        while self.active:
            try:
                # æ§åˆ¶å¸§ç‡
                current_time = time.time()
                sleep_time = max(0, last_frame_time + frame_interval - current_time)
                time.sleep(sleep_time)
                last_frame_time = current_time
                
                # è¯»å–è§†é¢‘å¸§
                ret, frame = self.cap.read()
                if not ret:
                    logging.warning("âš ï¸ è¯»å–å¸§å¤±è´¥ï¼Œè·³è¿‡")
                    continue
                
                # JPEGå‹ç¼©ï¼ˆé™ä½è´¨é‡ä»¥å‡å°å¸¦å®½ï¼‰
                _, img_encoded = cv2.imencode('.jpg', frame, [
                    int(cv2.IMWRITE_JPEG_QUALITY), 70
                ])
                
                # å‘é€è§†é¢‘æ•°æ®
                self.video_socket.sendto(img_encoded.tobytes(), (TARGET_IP, VIDEO_PORT))
                
                # æ›´æ–°å¸§è®¡æ•°
                self.frame_count += 1
                
                # æ¯ç§’æ˜¾ç¤ºå¸§ç‡
                elapsed = time.time() - self.start_time
                if elapsed >= 1.0:
                    fps = self.frame_count / elapsed
                    logging.info(f"ğŸ“¹ è§†é¢‘å¸§ç‡: {fps:.1f} FPS")
                    self.frame_count = 0
                    self.start_time = time.time()
                    
            except Exception as e:
                logging.error(f"ğŸ”´ è§†é¢‘æ•è·é”™è¯¯: {str(e)}")
                time.sleep(0.1)

    def start_streaming(self):
        """å¯åŠ¨éŸ³è§†é¢‘æµä¼ è¾“"""
        logging.info(f"ğŸš€ ç›®æ ‡åœ°å€: {TARGET_IP}:{VIDEO_PORT}(è§†é¢‘)/{AUDIO_PORT}(éŸ³é¢‘)")
        
        # å¯åŠ¨éŸ³é¢‘é‡‡é›†
        audio_started = self.start_audio_capture()
        
        # å¯åŠ¨è§†é¢‘çº¿ç¨‹
        video_thread = threading.Thread(target=self.video_capture_thread)
        video_thread.daemon = True
        video_thread.start()
        
        # ç­‰å¾…é€€å‡º
        try:
            while self.active:
                time.sleep(1)
        except KeyboardInterrupt:
            self.active = False
        finally:
            self.cleanup()

    def cleanup(self):
        """èµ„æºæ¸…ç†"""
        self.active = False
        time.sleep(0.1)  # ç»™çº¿ç¨‹æ—¶é—´é€€å‡º
        
        # å…³é—­æ‘„åƒå¤´
        if hasattr(self.cap, 'release'):
            try:
                self.cap.release()
            except:
                pass
        
        # å…³é—­éŸ³é¢‘è¿›ç¨‹
        if self.audio_process and self.audio_process.poll() is None:
            try:
                self.audio_process.terminate()
                self.audio_process.wait(timeout=1.0)
            except:
                pass
        
        # å…³é—­å¥—æ¥å­—
        self.video_socket.close()
        self.audio_socket.close()
        
        logging.info("âœ… èµ„æºå·²é‡Šæ”¾")

if __name__ == "__main__":
    try:
        streamer = MediaStreamer()
        streamer.start_streaming()
    except Exception as e:
        logging.error(f"ğŸ”´ ç¨‹åºå¼‚å¸¸: {str(e)}")


#!/usr/bin/env python3
# receiver.py - éŸ³è§†é¢‘æ¥æ”¶ç«¯ï¼ˆå®Œæ•´ç‰ˆï¼‰
import cv2
import numpy as np
import socket
import threading
import time
import logging
import sys
import sounddevice as sd
import queue

# ============== é…ç½®åŒºåŸŸ ==============
VIDEO_PORT = 5002
AUDIO_PORT = 5003
DISPLAY_SIZE = (640, 480)  # æ˜¾ç¤ºçª—å£å¤§å°
BUFFER_SIZE = 65535        # UDPç¼“å†²åŒºå¤§å°
AUDIO_SAMPLE_RATE = 44100 # éŸ³é¢‘é‡‡æ ·ç‡
AUDIO_CHANNELS = 1        # éŸ³é¢‘é€šé“æ•°
# =====================================

class MediaReceiver:
    def __init__(self):
        # çŠ¶æ€æ§åˆ¶
        self.running = True
        self.window_name = "Loongson Stream"
		
		# åˆå§‹åŒ–å…³é”®å±æ€§ï¼ˆæ·»åŠ ä¸‹é¢è¿™ä¸€è¡Œä¿®å¤é”™è¯¯ï¼‰
        self.last_resize_time = time.time()  # è®°å½•çª—å£æ“ä½œæ—¶é—´
        self.last_video_fps = 0.0  # æ·»åŠ è¿™ä¸€è¡Œè§£å†³"last_video_fps"é”™è¯¯
        self.frame_queue = queue.Queue()
        self.audio_queue = queue.Queue()
		# åˆ›å»ºçª—å£ä½†ä¸ç«‹å³è°ƒæ•´å¤§å°
        cv2.namedWindow(self.window_name, cv2.WINDOW_NORMAL)
        
        # ç½‘ç»œå¥—æ¥å­—
        self.video_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self.audio_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        
        # å¥—æ¥å­—è®¾ç½®
        self.video_socket.setsockopt(socket.SOL_SOCKET, socket.SO_RCVBUF, 10 * 1024 * 1024)
        self.audio_socket.setsockopt(socket.SOL_SOCKET, socket.SO_RCVBUF, 10 * 1024 * 1024)
        
        # å¸§é˜Ÿåˆ—
        self.frame_queue = queue.Queue(maxsize=2)  # è§†é¢‘å¸§é˜Ÿåˆ—
        
        # éŸ³é¢‘é˜Ÿåˆ—
        self.audio_queue = queue.Queue(maxsize=100)  # éŸ³é¢‘æ•°æ®é˜Ÿåˆ—
        
        # æ€§èƒ½è®¡æ•°å™¨
        self.video_frame_count = 0
        self.audio_packet_count = 0
        self.start_time = time.time()
        
        # é…ç½®æ—¥å¿—
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s [%(levelname)s] %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S',
            handlers=[logging.StreamHandler(sys.stdout)]
        )
        
        # åˆå§‹åŒ–éŸ³é¢‘è¾“å‡º
        self.init_audio_output()
        
        # åˆå§‹åŒ–è§†é¢‘çª—å£
        cv2.namedWindow("Loongson Stream", cv2.WINDOW_NORMAL)
        cv2.resizeWindow("Loongson Stream", DISPLAY_SIZE[0], DISPLAY_SIZE[1])
        cv2.moveWindow("Loongson Stream", 100, 100)
        
        logging.info("âœ… æ¥æ”¶ç«¯åˆå§‹åŒ–å®Œæˆ")

    def init_audio_output(self):
        """åˆå§‹åŒ–éŸ³é¢‘è¾“å‡ºæµ"""
        try:
            # æŸ¥è¯¢å¯ç”¨çš„éŸ³é¢‘è¾“å‡ºè®¾å¤‡
            devices = sd.query_devices()
            output_device = None
            
            # ä¼˜å…ˆé€‰æ‹©æ”¯æŒ44100Hzé‡‡æ ·çš„è®¾å¤‡
            for idx, dev in enumerate(devices):
                if dev['max_output_channels'] > 0 and AUDIO_SAMPLE_RATE <= dev['default_samplerate']:
                    output_device = idx
                    break
            
            if output_device is None:
                output_device = sd.default.device[1]
            
            # åˆ›å»ºéŸ³é¢‘è¾“å‡ºæµ
            self.audio_stream = sd.OutputStream(
                samplerate=AUDIO_SAMPLE_RATE,
                channels=AUDIO_CHANNELS,
                dtype='int16',
                blocksize=1024,
                device=output_device,
                callback=self.audio_callback
            )
            
            self.audio_stream.start()
            logging.info(f"ğŸ”Š éŸ³é¢‘è¾“å‡ºå·²å¯åŠ¨ @ {AUDIO_SAMPLE_RATE}Hz (è®¾å¤‡: {devices[output_device]['name']})")
            
        except Exception as e:
            logging.error(f"âŒ éŸ³é¢‘è¾“å‡ºåˆå§‹åŒ–å¤±è´¥: {str(e)}")
            self.audio_stream = None

    def audio_callback(self, outdata, frames, time_info, status):
        """éŸ³é¢‘æ’­æ”¾å›è°ƒå‡½æ•°"""
        if self.audio_queue.empty():
            outdata.fill(0)  # é˜Ÿåˆ—ä¸ºç©ºæ—¶è¾“å‡ºé™éŸ³
            return
        
        try:
            # ä»é˜Ÿåˆ—è·å–éŸ³é¢‘æ•°æ®
            audio_data = self.audio_queue.get_nowait()
            outdata[:] = np.frombuffer(audio_data, dtype=np.int16).reshape(frames, AUDIO_CHANNELS)
        except queue.Empty:
            outdata.fill(0)
        except Exception as e:
            logging.error(f"ğŸ”´ éŸ³é¢‘æ’­æ”¾é”™è¯¯: {str(e)}")
            outdata.fill(0)

    def video_receive_thread(self):
        """è§†é¢‘æ¥æ”¶çº¿ç¨‹"""
        logging.info("ğŸ“¹ è§†é¢‘æ¥æ”¶çº¿ç¨‹å¯åŠ¨")
        
        # ç»‘å®šç«¯å£
        self.video_socket.bind(('0.0.0.0', VIDEO_PORT))
        self.video_socket.settimeout(0.1)
        
        while self.running:
            try:
                # æ¥æ”¶UDPæ•°æ®åŒ…
                data, _ = self.video_socket.recvfrom(BUFFER_SIZE)
                
                # è½¬æ¢ä¸ºå›¾åƒå¸§
                img_array = np.frombuffer(data, dtype=np.uint8)
                frame = cv2.imdecode(img_array, cv2.IMREAD_COLOR)
                
                if frame is not None:
                    # æ·»åŠ åˆ°å¸§é˜Ÿåˆ—
                    try:
                        self.frame_queue.put_nowait(frame)
                        self.video_frame_count += 1
                    except queue.Full:
                        pass  # é˜Ÿåˆ—æ»¡æ—¶è·³è¿‡
                
                # æ¯ç§’æ˜¾ç¤ºæ¥æ”¶ç»Ÿè®¡
                elapsed = time.time() - self.start_time
                if elapsed > 1.0:
                    fps = self.video_frame_count / elapsed
                    logging.info(f"ğŸ“¦ æ¥æ”¶å¸§ç‡: {fps:.1f} FPS")
                    self.video_frame_count = 0
                    self.start_time = time.time()
                    
            except socket.timeout:
                continue  # è¶…æ—¶æ­£å¸¸
            except Exception as e:
                logging.error(f"ğŸ”´ è§†é¢‘æ¥æ”¶é”™è¯¯: {str(e)}")

    def audio_receive_thread(self):
        """éŸ³é¢‘æ¥æ”¶çº¿ç¨‹"""
        logging.info("ğŸ”Š éŸ³é¢‘æ¥æ”¶çº¿ç¨‹å¯åŠ¨")
        
        # ç»‘å®šç«¯å£
        self.audio_socket.bind(('0.0.0.0', AUDIO_PORT))
        self.audio_socket.settimeout(0.1)
        
        while self.running:
            try:
                # æ¥æ”¶éŸ³é¢‘æ•°æ®
                data, _ = self.audio_socket.recvfrom(4096)
                
                # æ·»åŠ åˆ°éŸ³é¢‘é˜Ÿåˆ—
                try:
                    self.audio_queue.put_nowait(data)
                    self.audio_packet_count += 1
                except queue.Full:
                    pass  # é˜Ÿåˆ—æ»¡æ—¶è·³è¿‡
                
            except socket.timeout:
                continue  # è¶…æ—¶æ­£å¸¸
            except Exception as e:
                logging.error(f"ğŸ”´ éŸ³é¢‘æ¥æ”¶é”™è¯¯: {str(e)}")

    def display_thread(self):
        """è§†é¢‘æ˜¾ç¤ºçº¿ç¨‹"""
        FONT = cv2.FONT_HERSHEY_SIMPLEX
        
        # OpenCV 3.2.0å…¼å®¹æ€§å¤„ç†
        self.last_resize_time = time.time()
        display_size = (640, 480)  # æ˜ç¡®æŒ‡å®šæ˜¾ç¤ºå°ºå¯¸
    
        try:
            # å°è¯•è°ƒæ•´çª—å£å¤§å°
            cv2.resizeWindow(self.window_name, display_size[0], display_size[1])
        except:
            # æ—§ç‰ˆOpenCVå¯èƒ½éœ€è¦é¢å¤–çš„å»¶è¿Ÿ
            time.sleep(0.5)
            cv2.resizeWindow(self.window_name, display_size[0], display_size[1])
    
        # å¸§ç‡è®¡ç®—åˆå§‹åŒ–
        last_fps_time = time.time()
        frame_count = 0 
        
        while self.running:
            try:
                # å°è¯•è·å–æ–°å¸§
                frame = self.frame_queue.get(timeout=1.0)
                frame_count += 1
				# è®¡ç®—FPSï¼ˆä»£æ›¿ç›´æ¥ä½¿ç”¨last_video_fpsï¼‰
                current_time = time.time()
                if current_time - last_fps_time >= 1.0:
                    fps = frame_count / (current_time - last_fps_time)
                    self.last_video_fps = fps  # æ›´æ–°å±æ€§å€¼
                    logging.info(f"æ¥æ”¶å¸§ç‡ï¼š{fps:.1f} FPS")
                    frame_count = 0
                    last_fps_time = current_time
            
                # æ·»åŠ å¸§ç‡æ˜¾ç¤º
                fps_text = f"FPS: {self.last_video_fps:.1f}"
                cv2.putText(frame, fps_text, (10, 30), 
                             cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
                # æ›´æ–°è¿æ¥çŠ¶æ€
                connection_status = "å·²è¿æ¥"
                last_status_time = time.time()
                
                # åˆ›å»ºçŠ¶æ€è¦†ç›–å±‚
                overlay = frame.copy()
                cv2.rectangle(overlay, (0, 0), (frame.shape[1], 80), (0, 0, 0), -1)
                cv2.addWeighted(overlay, 0.5, frame, 0.5, 0, frame)
                
                # åˆ›å»ºè‹±æ–‡çŠ¶æ€ä¿¡æ¯
                fps_text = f"FPS: {self.last_video_fps:.1f}"
                status_text = f"Status: Connected"
                help_text = "Press 'q' to quit"
            
                # æ·»åŠ çŠ¶æ€ä¿¡æ¯ï¼ˆä½¿ç”¨è‹±æ–‡å­—ä½“ï¼‰
                cv2.putText(frame, fps_text, (10, 30), FONT, 0.7, (0, 255, 0), 2)
                cv2.putText(frame, status_text, (10, 60), FONT, 0.7, (0, 255, 0), 2)
                cv2.putText(frame, help_text, (frame.shape[1]-200, frame.shape[0]-10), 
                            FONT, 0.5, (0, 200, 200), 1)
                
                # æ˜¾ç¤ºå›¾åƒ
                cv2.imshow(self.window_name, frame)
                
            except queue.Empty:
                # æ˜¾ç¤ºç­‰å¾…ç”»é¢ï¼ˆä½¿ç”¨è‹±æ–‡ï¼‰
                waiting_img = np.zeros((DISPLAY_SIZE[1], DISPLAY_SIZE[0], 3), dtype=np.uint8)
                cv2.putText(waiting_img, "Status: Connecting...",
                            (50, DISPLAY_SIZE[1]//2-20), FONT, 0.8, (0, 200, 200), 2)
                cv2.putText(waiting_img, "Waiting for video stream",
                            (50, DISPLAY_SIZE[1]//2+20), FONT, 0.8, (0, 200, 200), 2)
                cv2.imshow("Loongson Stream", waiting_img)
            # æ£€æŸ¥é€€å‡ºé”®
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                self.running = False
                break

    def start(self):
        """å¯åŠ¨æ¥æ”¶ç«¯"""
        logging.info(f"ğŸ“¡ ç›‘å¬ç«¯å£: {VIDEO_PORT} (è§†é¢‘) | {AUDIO_PORT} (éŸ³é¢‘)")
        
        # å¯åŠ¨è§†é¢‘æ¥æ”¶çº¿ç¨‹
        video_thread = threading.Thread(target=self.video_receive_thread)
        video_thread.daemon = True
        video_thread.start()
        
        # å¯åŠ¨éŸ³é¢‘æ¥æ”¶çº¿ç¨‹
        audio_thread = threading.Thread(target=self.audio_receive_thread)
        audio_thread.daemon = True
        audio_thread.start()
        
        # åœ¨ä¸»çº¿ç¨‹è¿è¡Œæ˜¾ç¤º
        self.display_thread()
        
        # æ¸…ç†èµ„æº
        self.cleanup()

    def cleanup(self):
        """èµ„æºæ¸…ç†"""
        self.running = False
        cv2.destroyAllWindows()
        
        # å…³é—­å¥—æ¥å­—
        self.video_socket.close()
        self.audio_socket.close()
        
        # å…³é—­éŸ³é¢‘æµ
        if self.audio_stream:
            self.audio_stream.stop()
            self.audio_stream.close()
        
        logging.info("âœ… èµ„æºå·²é‡Šæ”¾")

if __name__ == "__main__":
    try:
        receiver = MediaReceiver()
        receiver.start()
    except Exception as e:
        logging.error(f"ğŸ”´ æ¥æ”¶ç«¯é”™è¯¯: {str(e)}")
